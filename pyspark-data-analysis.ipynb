{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0898d85d-a491-420c-8164-5f353a9151d1",
   "metadata": {},
   "source": [
    "# PySpark data analysis\n",
    "Based on [this post](https://towardsdatascience.com/beginners-guide-to-pyspark-bbe3b553b79f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5412ab0b-6377-4d59-adae-e0c154d2c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14fffd-6cf1-4a21-b39b-b1fc5e5a810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, lit, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75786e0c-33de-4484-859c-18c3531edf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(\"spark://localhost:7078\")\\\n",
    "        .appName(\"pyspark-data-analysis\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c2954-f90b-4e43-b1c8-896023aea40d",
   "metadata": {},
   "source": [
    "### Loading and analysing data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a94fe-e7f7-4618-baa0-302896f7e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a csv\n",
    "rdd_csv = spark.read.csv(\"./data/stocks_price_final.csv\", sep = \",\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0290baf-3fd7-415f-abb1-94eb9c800a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting number of records\n",
    "rdd_csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97148d-d1b7-488a-b2da-70f1a9d47095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing columns and data types identified\n",
    "rdd_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7316a53-0cb3-4469-889c-900c0435f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the schema to be used for the RRD during file loading\n",
    "schema = [\n",
    "    StructField('_c0', IntegerType(), True),\n",
    "    StructField('symbol', StringType(), True),\n",
    "    StructField('date', DateType(), True),\n",
    "    StructField('open', DoubleType(), True),\n",
    "    StructField('high', DoubleType(), True),\n",
    "    StructField('low', DoubleType(), True),\n",
    "    StructField('close', DoubleType(), True),\n",
    "    StructField('volume', IntegerType(), True),\n",
    "    StructField('adjusted', DoubleType(), True),\n",
    "    StructField('market.cap', StringType(), True),\n",
    "    StructField('sector', StringType(), True),\n",
    "    StructField('industry', StringType(), True),\n",
    "    StructField('exchange', StringType(), True),\n",
    "]\n",
    "\n",
    "structure = StructType(fields = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb29566-0adc-450f-88b8-92deb9dc5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a csv specifying schema\n",
    "rdd_csv = spark.read.csv(\"./data/stocks_price_final.csv\", sep = \",\", header = True, schema = structure )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6862f37-27d0-4ca5-b17e-4df68d81ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing columns and data types identified, you can also use .schema, .dtypes, .columns\n",
    "rdd_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcacdf-6056-4953-bb90-a82672b480cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first 20 records, you can also use .take(n), .head(n), .first()\n",
    "rdd_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120c277-fc8d-4784-90e1-a0af95ac9eac",
   "metadata": {},
   "source": [
    "### Querying and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1958e-d5dd-4e10-8c78-4af613a2ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "# Transforming to pandas is important for visualization purposes using matplotlib\n",
    "TSLA = rdd_csv.filter(col(\"symbol\") == lit(\"TSLA\")).toPandas()\n",
    "GME = rdd_csv.filter(col(\"symbol\") == lit(\"GME\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35b329-4b61-46d0-9d4a-3bafd6b8fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex = True, figsize = (30, 15))\n",
    "axes[0].plot(TSLA[\"date\"], TSLA[\"high\"], label = \"Highest price\")\n",
    "axes[0].plot(TSLA[\"date\"], TSLA[\"low\"], label = \"Lowest price\")\n",
    "axes[1].plot(GME[\"date\"], GME[\"high\"], label = \"Highest price\")\n",
    "axes[1].plot(GME[\"date\"], GME[\"low\"], label = \"Lowest price\")\n",
    "axes[0].set_title(\"Stock price time series for TSLA and GME\")\n",
    "axes[0].set_ylabel(\"Price\")\n",
    "axes[1].set_ylabel(\"Price\")\n",
    "plt.xlabel(\"Date\")\n",
    "axes[0].grid()\n",
    "axes[1].grid()\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee7a52-6115-48cd-acc1-00b23e2263ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_by_sector = rdd_csv.select([\"symbol\", \"sector\"]).groupBy(\"sector\").agg(countDistinct(\"symbol\").alias(\"n_companies\")).orderBy(col(\"n_companies\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411703a-2be4-418e-a241-5d12709df67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.barh(ncomp_by_sector[\"sector\"], ncomp_by_sector[\"n_companies\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7579d-c90b-44da-9793-8fa94ed39567",
   "metadata": {},
   "source": [
    "### Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb2308-3050-40de-9382-540c0fa5d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing data in JSON format\n",
    "rdd_csv.filter(col(\"symbol\") == lit(\"TSLA\")).select([\"date\", \"high\", \"low\"]).write.save(\"./data/TSLA_timeseries.csv\", format = \"csv\", header = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643955e-d0cb-400e-a6d9-12c3a9187d59",
   "metadata": {},
   "source": [
    "### Stoping Spark context and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850cce90-64e8-4d16-a65b-80c583524e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9eb47-a124-4dcb-9cf7-18e47cddbde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
